The speaker, Andrej, explains that he will demonstrate how to build a simple language model based on the Transformer neural network architecture, similar to the one used in ChatGPT. He states that they will use a small dataset called 'Tiny Shakespeare', which contains the works of Shakespeare. With this data, the model will be trained to guess the next character in a sequence based on the previous characters, effectively generating a 'Shakespeare-like' text. The ultimate goal is to help viewers understand how language models like ChatGPT work.