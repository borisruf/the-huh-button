In order to create a chat model using the GPT transformer architecture, we start by using the 'Tiny Shakespeare' dataset, which includes all of Shakespeare's works. This text is tokenized, or translated into numbers, with each character given a unique integer. This character level language model is created using Python for ease of understanding, although in practice, sub-word encodings are commonly used. The tokenized data is then wrapped into a torch.tensor to create a 'data tensor', which we can use for training the model.