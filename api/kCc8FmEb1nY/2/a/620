In the context being described, the speaker is discussing a process known as tokenization within a language model. He is describing how the characters in a given text are converted into integers, according to their designated place in the vocabulary. This is the "encoder". The "decoder" does the opposite - it translates the integers back into the original text. The example given is the tokenization of the text "hi there" into a list of integers like 46, 47, etc. The speaker is focusing on a model that works on a character level, meaning that it tokenizes single characters rather than chunks of text or "tokens".