The speaker is describing how their artificial intelligence model, ChatGPT, interacts with text. To read and generate text, it converts the text to numbers and back. This is done through a process called 'tokenization', using a 'tokenizer'. 

The tokenizer they use breaks down text into individual characters, like 'a' or 'b', each of which has a unique corresponding number. This process can be reversed to translate the numbers back to letters. 

However, there are other tokenizers that can break text merely into phrases or entire words, which reduces the number of tokens (or unique number-character pairs), but increases the range of numbers needed.

While these tokenizers may be more commonly used in practice due to efficiency, they will be using a simple character-level tokenizer for the sake of simplicity in their demonstration.