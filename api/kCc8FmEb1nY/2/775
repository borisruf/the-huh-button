The speaker, Andrej, is talking about creating a simplified version of the widely renowned artificial intelligence (AI) model, GPT (Generatively Pre-trained Transformer) which generates human-like text. He mentions that he will not use the vast information source, the internet, like the original GPT but instead, he plans to work with a much smaller dataset, 'Tiny Shakespeare'. He explains that the core task of the model will be to predict the next character based on the previous ones in a given sequence from Shakespeare's works. He then illustrates the process with an example where the letters 'o', 'm', 'i', 'n' are given to the model and the model predicts the next character is 'g'. This prediction is determined taking into account the patterns found in the dataset as the model trains on it. He intends to help viewers understand the basic underlying workings of such AI text-generating tools with this demonstration.