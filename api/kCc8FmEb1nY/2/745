The speaker wants to create a simplified version of the AI model Chat GPT, using the PyTorch library and a character-level language model. The speaker plans to train this model using a dataset called 'Tiny Shakespeare', a text file containing all of Shakespeare's works. 

The ultimate goal is to be able to predict characters in the text based on the given sequence of characters. 

Before training the model, the text data needs to be tokenized, which is the process of converting raw text into a sequence of integers. This process allows the model to understand and work with the text data. 

The speaker notes that for this exercise, a character-level tokenizer will be used, although sub-word or word-level tokenizers could be used in practice. 

Once the text is tokenized, it can be converted into a PyTorch tensor, which will be used to train the model.