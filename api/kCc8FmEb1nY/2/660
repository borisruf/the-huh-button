We're talking about how text is processed in AI language models such as ChatGPT. In these models, text is first converted, or encoded, into numbers. Each unique character, word, or chunk of text (known as a token) is assigned a unique number. This process is called tokenization. This simplifies task for the AI because machines understand numbers better than text. This encoding can be reversed to convert the numbers back into text, enabling the AI model to output human-readable responses. Various methods have been developed for this encoding process. The simple method described here assigns a unique number to each unique character in the text. But other more complex methods exist, for instance Google's 'sentence piece' method. The exact method used depends on the specific application and dataset.