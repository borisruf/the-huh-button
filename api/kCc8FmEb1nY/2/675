The 'sentence piece' is a system that encodes text into numbers. The way it does this is different from other systems and it uses a different vocabulary. It does this in a way we call a 'sub-word' tokenizer, which means it breaks down words into smaller parts, or 'sub-words', for encoding. This is different from the system we used here, where we broke down the text into characters. Both systems transform text into numbers, but they do it in different ways.