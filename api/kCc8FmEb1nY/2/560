Andrej explained that he intends to build a simple version of GPT, a language model, to demonstrate how these types of AI systems work. Using a neural network called Transformer and a small dataset containing all of Shakespeare's works, he plans to train the model to predict the most likely next character based on previous character sequences. Although he can't recreate full-scale GPT systems, Andrej hopes to show viewers how this basic language model works using Python and some basic understanding of calculus and statistics. He also mentioned that he has shared the codes he will use on Google Colab and Github to encourage viewers to try it out themselves.