Andrej explains that he's going to show viewers how to build a language model similar to ChatGPT, a remarkable AI that can generate different responses to text inputs. However, instead of using the whole internet, he'll use a smaller dataset - a compilation of all Shakespeare's works called 'Tiny Shakespeare'. He plans to train the system to predict the next character in a sequence of characters found in the Shakespeare data. After training, the system can generate texts that mimics Shakespeare's language. Although his code will work on a character-by-character basis, while ChatGPT works on a token (sub-word pieces) basis, the end results will be similar. He's also created a GitHub repository he calls 'Nano GPT' where he shares a simple implementation for training Transformers. His aim is to help viewers understand how Chat GPT works under the hood, and for this, viewers will need to know Python and some basic calculus and statistics.