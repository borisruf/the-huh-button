Andrej discussed how the AI software known as ChatGPT works. He wants to show how a Transformer-based language model can be built and trained. Gly mentioned a repository he made where he detailed how to train Transformers on any given text, even providing the code. He plans to use a dataset of Shakespeare's works and demonstrate how the Transformer can predict next characters based on previous ones. His goal with all this is to demystify how Chat GPT works and only requires fundamental knowledge of Python, calculus, and statistics to understand.