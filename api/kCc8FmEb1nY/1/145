The speaker is explaining how the AI system ChatGPT works. It is able to generate text in response to various prompts, and can come up with different responses each time due to its probabilistic nature. The speaker refers to ChatGPT as a 'language model' because it can predict the sequence of words based on the English language. The underlying neural network that enables this function is called 'Transformer', and it was proposed in a landmark paper titled "Attention is All You Need" published in 2017. When the speaker says "it comes from this paper in 2017," they are referring to the origin of the Transformer model used in ChatGPT.
