Andrej plans to build a Transformer-based language model, using 'Tiny Shakespeare' as a dataset. 'Tiny Shakespeare' is a file combining all works by Shakespeare. The goal is to train the Transformer to predict the next character from a given sequence of characters. The trained system will be able to generate text that resembles Shakespeareâ€™s writing style. Andrej will be demonstrating this process by writing the code from scratch in a Google Colab Jupyter notebook. He believes that this will help viewers understand how Chat GPT, a complex, production-grade language model, operates under the hood.