"Andrej explains in the video that he aims to demonstrate how to build and train a rudimentary version of Machine Learning tool 'ChatGPT' using a simple dataset known as 'Tiny Shakespeare'. He describes how ChatGPT uses a 'Transformer' neural network, which arose from a paper called 'Attention is all you need'. However, due to the complexity of ChatGPT, which has been trained on a significant portion of the internet, Andrej clarifies that he will only illustrate how to create a 'character-level' language model using Transformer-based language modeling. The ultimate goal is to make viewers understand and appreciate the workings of ChatGPT's underlying technology and how it continues to impact the field of AI. Note: Andrej has already written the training code for these transformers and it's available on his GitHub in a repository called Nano GPT."