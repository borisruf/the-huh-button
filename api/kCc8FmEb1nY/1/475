Andrej explains that he wishes to build a system similar to ChatGPT, which is an AI designed to craft text. However, he acknowledges that he cannot entirely reproduce ChatGPT due to its complexity. Instead, he proposes creating a Transformer-based language model using the 'Tiny Shakespeare' dataset, which includes the works of William Shakespeare. By training the Transformer on this dataset, he hopes it can predict character sequences that resemble Shakespeare's writing. He then introduces his pre-made repository, NanoGPT, which contains code for training Transformers on any text dataset. In the next part of the video, Andrej will teach viewers to develop this code from scratch using a Google Colab Jupyter notebook. His goal is to increase viewer's understanding of how the Chat GPT model works. All that is required for his audience is proficiency with Python, and basic understanding of calculus and statistics.