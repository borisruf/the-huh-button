In this lengthy passage, the speaker is delving into the finer details of artificial intelligence, specifically discussing language models. When referring to 'sub-word unit level', what they're talking about is tokenizing the models based on sub-words - which are smaller pieces of a complete word. Normally words would be broken into letters in order to establish patterns (e.g., character-level) but in this case, the tokenization happens at a sub-word level. This approach is commonly used in practice, as it helps with handling issues related to the morphological variance of different words, including languages where words can drastically change depending on their usage.
