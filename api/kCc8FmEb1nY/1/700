The instructor is describing the process of encoding in which text data, such as "hello world," are converted into a sequence or list of integers, or 'tokens'. It involves mapping each unique element of the input text (in this case, characters) to a unique integer. Decoding is the reverse process, translating the sequence of integers back into a text. This process is essential in natural language processing tasks, including language model training, because ML algorithms work with numeric data. The instructor notes that this explanation applies to a character-level language model involving individual characters. Other tokenizing schemas may involve sub-word units or entire words.