Andrej intends to teach the viewers about the workings of the Chat GPT system by creating a Transformer-based language model using a smaller datasetâ€”the 'Tiny Shakespeare'. Although he acknowledges they cannot reproduce the exact Chat GPT, this simplified model would provide an educational demonstration of how such systems generally function. Andrej plans to train the model to predict the next character in a sequence based on a context of past characters from Shakespeare's works. He would then use the trained system to generate text that mimics Shakespearean language. Andrej has already provided code for training Transformers on different types of text in his GitHub repository called 'nano GPT', and he plans to reproduce this repository from scratch in the tutorial, focusing primarily on defining the Transformer neural network itself.