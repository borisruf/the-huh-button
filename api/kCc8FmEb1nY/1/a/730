The speaker is discussing how different tokenization schemas can break down and represent the same input text in various ways. In their example of the phrase "hi there", their character-level model translated each character into a single integer, resulting in a longer list of integers. In contrast, Google's 'sentence piece' tokenizer breaks down the text into sub-word units, while OpenAI's 'tick token' library, which uses a 'byte pair encoding tokenizer', breaks it down into even fewer pieces. They highlight that these tokenizers can handle more complex vocabularies, with the 'tick token' library able to identify 50,000 potential tokens, versus the 65 their character-level model recognizes. The integers resulting from the 'tick token' tokenizer, while fewer, fall within a wider range (0 to 50,256) compared to those from the character-level model (0 to 64).