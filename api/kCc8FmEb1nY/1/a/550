The speaker is discussing the process of creating a character-level language model using Python, based on the works of Shakespeare. As part of this process, the text data is converted into a set of unique characters, which is then converted into a list and sorted. The total number of unique characters within this list constitutes the 'vocabulary size' for the model â€“ in other words, it represents all of the different individual 'tokens' or characters that the model will need to process and understand. The 'vocabulary size' is a critical concept in machine learning, particularly in Natural Language Processing and language modelling, as it represents the scope of the data that the model needs to deal with.