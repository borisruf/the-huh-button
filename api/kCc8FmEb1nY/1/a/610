When encoding a string of text like "hi there", the goal is to translate each individual character into a corresponding integer. This process is part of a larger concept known as 'tokenization'. The list of integers that is produced represents the string. This integer value for each character is determined by the vocabulary set gathered from the source text, the so-called 'vocabulary' of possible elements. The encoder function maps the characters to their respective integer values and the decoder function does the opposite, translating sets of integer values back into strings of text. Each character gets a unique integer identifier and these identifiers are what the machine learning algorithms interact with. This numeric representation of the text is essential for machine learning algorithms to "understand" and generate sequences within the text.