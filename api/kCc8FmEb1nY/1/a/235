The speaker is suggesting to train a Transformer-based language model using a smaller, more manageable data set which they refer to as their "favorite toy data set." This proposal is made in the context of trying to understand and replicate the functioning of ChatGPT, a cutting-edge AI language model, in a simplified manner. The speaker indicates that fully reproducing ChatGPT is complex and requires significant resources, including a large data set comprising a good chunk of the internet. Thus, to make the task of understanding and building a similar system more feasible, they suggest working with a smaller, simpler data set.