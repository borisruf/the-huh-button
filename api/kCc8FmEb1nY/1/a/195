ChatGPT works on the concept of a probabilistic system, providing multiple variations of responses to a single prompt. Essentially, it's a language model that generates sequences of words in a manner that resembles typical English conversation. The functioning and foundation of ChatGPT are based on the Transformer architecture, a neural network format introduced in the 2017 paper "Attention is all you need". This architecture, initially used for machine translation, became influential and was adopted in diverse AI applications, forming the core of ChatGPT.