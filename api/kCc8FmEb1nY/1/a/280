The speaker is explaining that they will use a dataset called Tiny Shakespeare, which contains all of Shakespeare's works, to train a transformer-based language model. This character-level language model will learn how characters follow each other in Shakespeare's prose and then generate characters in a similar fashion. This is achieved by training the Transformer neural network to look at a series of characters and predict what character is likely to come next based on the patterns it has learned from Shakespeare's works.