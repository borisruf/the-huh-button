The person is explaining how to build a text-based artificial intelligence (AI) model, with emphasis on language model known as ChatGPT. They explained the concept of the model, which works by recognizing the sequence of words or characters given and completes the sequence with an outcome. They go further to discuss the neural network that supports this model (Transformer), its origin and how it's been adapted into many AI applications. 

The speaker mentioned how they plan on training a Transformer-based language model using a small dataset called 'Tiny Shakespeare'. The aim is to model the patterns in this text, and once the system is trained, it can generate 'infinite' Shakespeare-like language. They have written the code to do all these and it is publicly available on their GitHub repository.

Finally, they mention the concept of tokenizing the text, which involves converting the raw text into a sequence of integers. The piece is an introduction into an AI programming class where participants are taught to build a simple language model using Python, knowledge of calculus and statistics and the PyTorch library for machine learning.