The speaker is explaining how they will train a Transformer-based character-level language model using the 'Tiny Shakespeare' data set. As part of the training, the Transformer neural network is tasked with predicting the next character in a sequence from the context of the previous characters. By doing this, the Transformer learns and models all the patterns that occur in the data set, such as common sequences of characters or words, helping it to generate text that closely resembles the original Shakespearean text.