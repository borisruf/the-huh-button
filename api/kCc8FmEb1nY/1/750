The speaker is discussing how one can use a subset of works by Shakespeare to train artificial intelligence models, specifically a Transformer-based language model. They will take all of the text from a dataset called 'Tiny Shakespeare', encode it and convert the characters of the text into integers (a process they refer to as tokenization) and then convert it into a torch.tensor, which is a multi-dimensional matrix containing elements of a single data type. This process allows the artificial intelligence models to learn and understand the patterns and sequence of the characters from 'Tiny Shakespeare'. Essentially, this process simplifies the text down to numerical representations that the program can analyze and learn from more efficiently.